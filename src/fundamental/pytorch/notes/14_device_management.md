# Device Management

## 游쀯릖 Spanish

El **manejo de dispositivos** es esencial en PyTorch. Cada **tensor** y **par치metro del modelo** debe residir en un dispositivo espec칤fico (CPU, GPU u otro acelerador). Si los tensores que interact칰an no est치n en el mismo dispositivo, el c칩digo fallar치 con un error com칰n de _Device Mismatch_.

### 1\. CPU vs. GPU (Aceleradores)

- **CPU (Central Processing Unit):** El dispositivo predeterminado. Es de prop칩sito general y procesa operaciones secuencialmente.
- **GPU (Graphics Processing Unit):** Un **acelerador** que procesa operaciones de tensores mucho m치s r치pido (t칤picamente de 10 a 15 veces m치s r치pido) porque las ejecuta en paralelo.
  - La tecnolog칤a m치s com칰n para GPUs NVIDIA en PyTorch es **CUDA**.

### 2\. Configuraci칩n y Elecci칩n del Dispositivo

- **Verificar Disponibilidad:** Se comprueba si PyTorch puede usar una GPU: `torch.cuda.is_available()`.
- **Patr칩n Seguro de Elecci칩n:** Se define el dispositivo para usar la GPU si est치 disponible; de lo contrario, se usa la CPU.
  ```python
  device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
  ```

### 3\. Mover Datos y Modelo al Dispositivo

**PyTorch no mueve los datos autom치ticamente; debes hacerlo manualmente.**

| Elemento              | 쮺u치ndo se mueve?               | Sintaxis                     | Nota Clave                                                                          |
| :-------------------- | :------------------------------ | :--------------------------- | :---------------------------------------------------------------------------------- |
| **Modelo**            | Una sola vez, al crearlo.       | `model.to(device)`           | Mueve todos los pesos y sesgos del modelo.                                          |
| **Datos (Batch)**     | Dentro del bucle, en cada lote. | `data = data.to(device)`     | Debe reasignarse, ya que `.to()` crea un **nuevo** tensor.                          |
| **Etiquetas/Targets** | Dentro del bucle, en cada lote. | `target = target.to(device)` | Las etiquetas tambi칠n son tensores y deben coincidir con el dispositivo del modelo. |

- **Verificaci칩n:** Puedes revisar la ubicaci칩n de un tensor: `tensor.device`. Para un modelo, revisa la ubicaci칩n de uno de sus par치metros, por ejemplo: `model.layer_name.weight.device`.

### 4\. Gesti칩n de Memoria de la GPU

La memoria de la GPU es **limitada**.

- **Error Com칰n:** Si el modelo y el tama침o del lote (_batch size_) exceden la memoria disponible, se produce un error de "out of memory".
- **`batch_size` Importa:** Un **`batch_size` demasiado grande** es la causa m치s com칰n de errores de memoria en la GPU.
- **Soluci칩n:** Si recibes un error de memoria, la primera soluci칩n es **reducir el tama침o del lote** (un buen punto de partida suele ser 32 o 64).

## 游섫릖 English

**Device management** is essential in PyTorch. Every **tensor** and **model parameter** must reside on a specific device (CPU, GPU, or other accelerator). If interacting tensors are not on the same device, the code will crash with a common **Device Mismatch** error.

### 1\. CPU vs. GPU (Accelerators)

- **CPU (Central Processing Unit):** The default device. It's general-purpose and processes operations sequentially.
- **GPU (Graphics Processing Unit):** An **accelerator** that processes tensor operations much faster (typically 10-15x faster) by executing them in parallel.
  - The most common technology for NVIDIA GPUs in PyTorch is **CUDA**.

### 2\. Setup and Device Selection

- **Check Availability:** You check if PyTorch can use a GPU: `torch.cuda.is_available()`.
- **Safe Selection Pattern:** Define the device to use the GPU if available; otherwise, use the CPU.
  ```python
  device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
  ```

### 3\. Moving Data and Model to Device

**PyTorch will not move data for you automatically; you must do it manually.**

| Element            | When to Move?                     | Syntax                       | Key Note                                                     |
| :----------------- | :-------------------------------- | :--------------------------- | :----------------------------------------------------------- |
| **Model**          | Once, upon creation.              | `model.to(device)`           | Moves all the model's weights and biases.                    |
| **Data (Batch)**   | Inside the loop, for every batch. | `data = data.to(device)`     | **Must be reassigned,** as `.to()` creates a **new** tensor. |
| **Labels/Targets** | Inside the loop, for every batch. | `target = target.to(device)` | Labels are also tensors and must match the model's device.   |

- **Verification:** You can check a tensor's location: `tensor.device`. For a model, check the location of one of its parameters, e.g., `model.layer_name.weight.device`.

### 4\. GPU Memory Management

GPU memory is **limited**.

- **Common Error:** If the model and the **batch size** exceed the available memory, an "out of memory" error will occur.
- **Batch Size Matters:** An **overly large `batch_size`** is the most common cause of GPU memory errors.
- **Fix:** If you get a memory error, the first solution is to **lower your batch size** (a common starting point is 32 or 64).
